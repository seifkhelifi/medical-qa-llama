program: train.py
command:
  - sh
  - -lc
  - >
    torchrun --nproc_per_node=2 train.py
method: bayes
metric:
  name: proxy_val_loss
  goal: minimize
parameters:
  learning_rate:
    distribution: log_uniform_values
    min: 1.0e-4
    max: 3.0e-4
  warmup_ratio:
    values: [0.00, 0.03, 0.06]
  weight_decay:
    values: [0.0, 0.01]
  lr_scheduler_type:
    values: ["linear", "cosine"]
  lora_r:
    values: [4, 8, 16]
  lora_alpha:
    values: [8, 16, 32]
  lora_dropout:
    values: [0.0, 0.05]
  max_seq_length:
    values: [384, 512]      # fast proxy
  per_device_train_batch_size:
    values: [32]            # you have headroom; GAS=1
  gradient_accumulation_steps:
    values: [1]
  max_steps:
    values: [101]           # your fast loop
  eval_subset_size:
    values: [1000]          # eval only on 1k, once at the end
