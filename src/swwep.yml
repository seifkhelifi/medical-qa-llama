program: train.py
method: bayes
metric:
  name: proxy_val_loss
  goal: minimize
parameters:
  learning_rate:
    distribution: log_uniform_values
    min: 1.0e-4
    max: 3.0e-4
  warmup_ratio:
    values: [0.0, 0.03, 0.06]
  weight_decay:
    values: [0.0, 0.01]
  lr_scheduler_type:
    values: ["linear", "cosine"]
  lora_r:
    values: [4, 8, 16]
  lora_alpha:
    values: [8, 16, 32]
  lora_dropout:
    values: [0.0, 0.05]
  max_seq_length:
    values: [384, 512]   # proxy, faster than 1024
  per_device_train_batch_size:
    values: [8]          # safe on 10 GB T4; keep fixed in proxy
  gradient_accumulation_steps:
    values: [4]          # keep effective batch stable
  max_steps:
    values: [40]         # proxy: ~minutes, not hours
  eval_every:
    values: [40]         # 1 eval at the end of proxy trial
